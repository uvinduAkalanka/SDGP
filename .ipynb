{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4feea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8ab5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3638e11b",
   "metadata": {},
   "source": [
    "### STEP -1 Initializing CNN\n",
    "##### SELECTING THE MODEL FROM 2 MODELS OF KERAS.MODELS(SEQUENTIAL AND FUNTIONAL)\n",
    "##### creating object for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f030094",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b6715",
   "metadata": {},
   "source": [
    "### STEP 2- adding first layer -it is convolution layer for the CNN architecture\n",
    "##### arguments   Convolution2D - contains the feature of the image.32 means that 32 type of different filters for the model tuple. \"(3,3)\" represent the size of the filter (convolution type)\n",
    "#### input shape parameter- the size of the images that is going to be fed in to the CNN (64,64,3)==(hight,width ,RGB colors )\n",
    "#### ACTIVATION parameter -no images are linearly related to the each other(to introduce the non-linearity relu is the best\n",
    "\n",
    "#### polling layer 1 -specify the size the pooling matrix there. usage- reduce the risk of over fitting the images while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436a09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Convolution2D(32,(3,3),input_shape = (64,64,3), activation = 'relu'))\n",
    "sdgp_model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae941eae",
   "metadata": {},
   "source": [
    "### STEP 3- Adding second Convolution layer to the model and poooling the layer \n",
    "### (this  time no need to add input size of the layer because it is already done with the first layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34776b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Convolution2D(32,(3,3), activation = 'relu'))\n",
    "sdgp_model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417dbb6e",
   "metadata": {},
   "source": [
    "### STEP 4- Flattening the layers\n",
    "##### purpose of using flatten \n",
    "#####   - converting the 2D matrix that are coming trough the convolutiion and maxpooling layers to one diamentional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83457e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d7a29",
   "metadata": {},
   "source": [
    "### STEP 5- Full_Connection\n",
    "#### Purpuse of using full connection -- passing earlier computed whole data to the articitial nural network\n",
    "#### for that  dense class is been used\n",
    "#### 6 denses are used (all the funtions are hidden layers only can see in the back end calling)\n",
    "#### in dense \"units represents the number of neurons to the layer\n",
    "#### after units activation function is been used to indroduce non-linearity to the layer\n",
    "#### last layer  (the output layer) -   (units=8)== classes that are in the dataset(output layer\"s unit always == number of classes. softmax is used to catagorical classification here (0 to 7 will be outputted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdbd990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Dense(units=32,activation = 'relu')) \n",
    "\n",
    "sdgp_model.add(Dense(units=64,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=128,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=256,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=256,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=8,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d970cf",
   "metadata": {},
   "source": [
    "### STEP 6-Compiling CNN (COMPILE THE MODEL TO SIGLE UNIT)\n",
    "##### OPTIMISER - for high training efficiancy / REASON FOR  ADAM OPTIMISER USED -- it has adaptive learining environment(whenever training the model it will detect the errors and the lose function and automatically addapting learning rates and it helps to increase accuracy gratually)\n",
    "#### LOSS - this is categorical crossentropy(the reason to use- this project is with multiple classes) this will calculate errors  and predication and actuall result and passes those imformation  to training process to update bias in rats.so  the final result effect for the model is, training accuracy will be increased\n",
    "#### MATRIX - this is porforming matrix(purpose- whenever the model  training happaning if it needs to evaluate(accuracy or losse) the model it can be done by MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97986a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfd19a",
   "metadata": {},
   "source": [
    "### STEP 7 - Fitting CNN to images\n",
    "##### importing the preproccing libery from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff655dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358a071",
   "metadata": {},
   "source": [
    "##### initiating the object to pre-proccessing\n",
    "#### RESCALE- rescaling the taken matrix value within the range of 0 to 1 that is why  \"1./255\" used here\n",
    "#### SHEAR_RANGE - shear the images\n",
    "#### ZOOM_RANGE - ZOOM THE IMAGE OF THE EASYNESS OF EXTACTION OF THE FEATURES OF THE IMAGES\n",
    "#### HORIZONTAL_FLIP - solve the possions matters  , it will randomically flip the images while training so the model will be able to detect images with various postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75bbd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, # To rescaling the image in range of [0,1]\n",
    "                                   shear_range = 0.2, # To randomly shear the images \n",
    "                                   zoom_range = 0.2, # To randomly zoom the images\n",
    "                                   horizontal_flip = True) #  for randomly flipping half of the images horizontally "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56760f7",
   "metadata": {},
   "source": [
    "### STEP 8 AND 9\n",
    "####  FLOW_FROM THE DIRECTORY - is used to get the labels from the directory folders so do not want to add labels manually\n",
    "#### TARGET_SIZE - this must be same as the input shape in the convolution layers\n",
    "#### CLASS_MODE - moode of the classificating either the binary(only comes output as true or false becase its not fitting to this project) or categoroal (suitable for multi class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce1cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the data...\n",
      "\n",
      "Found 2912 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "print(\"\\nTraining the data...\\n\")\n",
    "training_set = train_datagen.flow_from_directory('E:\\\\ALL_ABOUT_SDGP\\\\myBestDataset2\\\\train',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size=12, #Total no. of batches\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7f51a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1247 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('E:\\\\ALL_ABOUT_SDGP\\\\myBestDataset2\\\\validation',\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=12,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae0978",
   "metadata": {},
   "source": [
    "### STEP 10- FIT THE TRAINING AND TESTING  IMAGES TO THE MODEL\n",
    "##### STEPS_PER_EPOCH - all the training images\n",
    "##### EPOCHS - TOTAL OF ITERTATION OF THE TRAINING( *****THIS SHOULD ME DEVISIBLE BY THE BTACH SIZE******)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e551381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "243/243 [==============================] - 320s 1s/step - loss: 0.6791 - accuracy: 0.6896 - val_loss: 0.9436 - val_accuracy: 0.6014\n",
      "Epoch 2/20\n",
      "243/243 [==============================] - 309s 1s/step - loss: 0.6498 - accuracy: 0.7146 - val_loss: 1.0123 - val_accuracy: 0.6071\n",
      "Epoch 3/20\n",
      "243/243 [==============================] - 309s 1s/step - loss: 0.6794 - accuracy: 0.6985 - val_loss: 1.0702 - val_accuracy: 0.5349\n",
      "Epoch 4/20\n",
      "243/243 [==============================] - 308s 1s/step - loss: 0.6200 - accuracy: 0.7188 - val_loss: 0.9969 - val_accuracy: 0.6175\n",
      "Epoch 5/20\n",
      "243/243 [==============================] - 307s 1s/step - loss: 0.6283 - accuracy: 0.7177 - val_loss: 1.0348 - val_accuracy: 0.6175\n",
      "Epoch 6/20\n",
      "243/243 [==============================] - 310s 1s/step - loss: 0.6611 - accuracy: 0.7119 - val_loss: 1.0419 - val_accuracy: 0.6199\n",
      "Epoch 7/20\n",
      "243/243 [==============================] - 304s 1s/step - loss: 0.6159 - accuracy: 0.7222 - val_loss: 1.1656 - val_accuracy: 0.6030\n",
      "Epoch 8/20\n",
      "243/243 [==============================] - 310s 1s/step - loss: 0.6035 - accuracy: 0.7263 - val_loss: 1.2194 - val_accuracy: 0.6055\n",
      "Epoch 9/20\n",
      "243/243 [==============================] - 311s 1s/step - loss: 0.5987 - accuracy: 0.7253 - val_loss: 1.0196 - val_accuracy: 0.6191\n",
      "Epoch 10/20\n",
      "243/243 [==============================] - 308s 1s/step - loss: 0.5917 - accuracy: 0.7266 - val_loss: 1.1774 - val_accuracy: 0.6167\n",
      "Epoch 11/20\n",
      "243/243 [==============================] - 307s 1s/step - loss: 0.5920 - accuracy: 0.7390 - val_loss: 1.0763 - val_accuracy: 0.6263\n",
      "Epoch 12/20\n",
      "243/243 [==============================] - 308s 1s/step - loss: 0.5913 - accuracy: 0.7297 - val_loss: 1.2512 - val_accuracy: 0.5846\n",
      "Epoch 13/20\n",
      "243/243 [==============================] - 306s 1s/step - loss: 0.6052 - accuracy: 0.7311 - val_loss: 1.0285 - val_accuracy: 0.6127\n",
      "Epoch 14/20\n",
      "243/243 [==============================] - 309s 1s/step - loss: 0.6192 - accuracy: 0.7263 - val_loss: 0.9924 - val_accuracy: 0.6255\n",
      "Epoch 15/20\n",
      "243/243 [==============================] - 309s 1s/step - loss: 0.5629 - accuracy: 0.7407 - val_loss: 1.0783 - val_accuracy: 0.6231\n",
      "Epoch 16/20\n",
      "243/243 [==============================] - 308s 1s/step - loss: 0.5616 - accuracy: 0.7442 - val_loss: 1.1832 - val_accuracy: 0.6455\n",
      "Epoch 17/20\n",
      "243/243 [==============================] - 309s 1s/step - loss: 0.5403 - accuracy: 0.7548 - val_loss: 1.1482 - val_accuracy: 0.6447\n",
      "Epoch 18/20\n",
      "243/243 [==============================] - 311s 1s/step - loss: 0.6147 - accuracy: 0.7315 - val_loss: 1.0622 - val_accuracy: 0.6167\n",
      "Epoch 19/20\n",
      "243/243 [==============================] - 306s 1s/step - loss: 0.5603 - accuracy: 0.7483 - val_loss: 1.1514 - val_accuracy: 0.6095\n",
      "Epoch 20/20\n",
      "243/243 [==============================] - 309s 1s/step - loss: 0.5293 - accuracy: 0.7596 - val_loss: 1.0932 - val_accuracy: 0.6504\n"
     ]
    }
   ],
   "source": [
    "sdgp_model_hist=sdgp_model.fit(training_set,\n",
    "                         steps_per_epoch=len(training_set),\n",
    "                         epochs = 20, # Total no. of epochs\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = len(test_set)) # Total testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0471e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.save(\"E:\\\\ALL_ABOUT_SDGP\\\\finalModelTraining\\\\sdgpModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f95b87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe971d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_metric(cm,classes,normalize=False,title='Conflusion metrix',cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar\n",
    "    tick_mark=np.arange(len(classes))\n",
    "    plt.xticks(tick_mark,classes,rotation=45)\n",
    "    plt.yticks(tick_mark,classes)\n",
    "    if normalize:\n",
    "        cm=cm.astype(('flot')/cm.sum(axis==1)[:,np.mewaxis])\n",
    "        print('confusion matrix, withouy normalitation')\n",
    "    else:\n",
    "        print('confusion matrix, withouy normalitation')\n",
    "    print(cm)\n",
    "    thresh=cm.max()/2\n",
    "    for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):\n",
    "        plt.text(j,i,cm[i,j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i,j]>thresh else \"black\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"true labels\")\n",
    "    plt.xlabel(\"Prediction\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf1b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rounded_predictions=65.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8418f7ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13652\\2105690672.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrounded_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcm_plot_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"0\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"3\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"6\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"7\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'float'>"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(y_true=test_set.classes,y_pred=rounded_predictions)\n",
    "\n",
    "cm_plot_labels=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7dd667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "878f30ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13652\\12644144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_confusion_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm_plot_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"conflision metrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "plot_confusion_metric(cm=cm,classes=cm_plot_labels,title=\"conflision metrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0421af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pytest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
