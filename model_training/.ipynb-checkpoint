{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4feea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3638e11b",
   "metadata": {},
   "source": [
    "### STEP -1 Initializing CNN\n",
    "##### SELECTING THE MODEL FROM 2 MODELS OF KERAS.MODELS(SEQUENTIAL AND FUNTIONAL)\n",
    "##### creating object for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f030094",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b6715",
   "metadata": {},
   "source": [
    "### STEP 2- adding first layer -it is convolution layer for the CNN architecture\n",
    "##### arguments   Convolution2D - contains the feature of the image.32 means that 32 type of different filters for the model tuple. \"(3,3)\" represent the size of the filter (convolution type)\n",
    "#### input shape parameter- the size of the images that is going to be fed in to the CNN (64,64,3)==(hight,width ,RGB colors )\n",
    "#### ACTIVATION parameter -no images are linearly related to the each other(to introduce the non-linearity relu is the best\n",
    "\n",
    "#### polling layer 1 -specify the size the pooling matrix there. usage- reduce the risk of over fitting the images while training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436a09a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Convolution2D(32,(3,3),input_shape = (64,64,3), activation = 'relu'))\n",
    "sdgp_model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae941eae",
   "metadata": {},
   "source": [
    "### STEP 3- Adding second Convolution layer to the model and poooling the layer \n",
    "### (this  time no need to add input size of the layer because it is already done with the first layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34776b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Convolution2D(32,(3,3), activation = 'relu'))\n",
    "sdgp_model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417dbb6e",
   "metadata": {},
   "source": [
    "### STEP 4- Flattening the layers\n",
    "##### purpose of using flatten \n",
    "#####   - converting the 2D matrix that are coming trough the convolutiion and maxpooling layers to one diamentional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83457e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82c9c3",
   "metadata": {},
   "source": [
    "### Full_Connection\n",
    "### STEP 5- Full_Connection\n",
    "#### Purpuse of using full connection -- passing earlier computed whole data to the articitial nural network\n",
    "#### for that  dense class is been used\n",
    "#### 6 denses are used (all the funtions are hidden layers only can see in the back end calling)\n",
    "#### in dense \"units represents the number of neurons to the layer\n",
    "#### after units activation function is been used to indroduce non-linearity to the layer\n",
    "#### last layer  (the output layer) -   (units=8)== classes that are in the dataset(output layer\"s unit always == number of classes. softmax is used to catagorical classification here (0 to 7 will be outputted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbd990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.add(Dense(units=32,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=64,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=128,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=256,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=256,activation = 'relu'))\n",
    "\n",
    "sdgp_model.add(Dense(units=8,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa128f",
   "metadata": {},
   "source": [
    "### Compiling CNN to simple peace\n",
    "### STEP 6-Compiling CNN (COMPILE THE MODEL TO SIGLE UNIT)\n",
    "##### OPTIMISER - for high training efficiancy / REASON FOR  ADAM OPTIMISER USED -- it has adaptive learining environment(whenever training the model it will detect the errors and the lose function and automatically addapting learning rates and it helps to increase accuracy gratually)\n",
    "#### LOSS - this is categorical crossentropy(the reason to use- this project is with multiple classes) this will calculate errors  and predication and actuall result and passes those imformation  to training process to update bias in rats.so  the final result effect for the model is, training accuracy will be increased\n",
    "#### MATRIX - this is porforming matrix(purpose- whenever the model  training happaning if it needs to evaluate(accuracy or losse) the model it can be done by MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97986a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a0a5e",
   "metadata": {},
   "source": [
    "### Fitting CNN to images\n",
    "### STEP 7 - Fitting CNN to images\n",
    "##### importing the preproccing libery from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ff655dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75bbd3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, # To rescaling the image in range of [0,1]\n",
    "                                   shear_range = 0.2, # To randomly shear the images \n",
    "                                   zoom_range = 0.2, # To randomly zoom the images\n",
    "                                   horizontal_flip = True) #  for randomly flipping half of the images horizontally "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3826009f",
   "metadata": {},
   "source": [
    "##### initiating the object to pre-proccessing\n",
    "#### RESCALE- rescaling the taken matrix value within the range of 0 to 1 that is why  \"1./255\" used here\n",
    "#### SHEAR_RANGE - shear the images\n",
    "#### ZOOM_RANGE - ZOOM THE IMAGE OF THE EASYNESS OF EXTACTION OF THE FEATURES OF THE IMAGES\n",
    "#### HORIZONTAL_FLIP - solve the possions matters  , it will randomically flip the images while training so the model will be able to detect images with various postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ce1cce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the data...\n",
      "\n",
      "Found 2912 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "print(\"\\nTraining the data...\\n\")\n",
    "training_set = train_datagen.flow_from_directory('E:\\\\ALL_ABOUT_SDGP\\\\myBestDataset2\\\\train',\n",
    "                                                target_size=(64,64),\n",
    "                                                batch_size=12, #Total no. of batches\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69bdf2d",
   "metadata": {},
   "source": [
    "### STEP 8 AND 9\n",
    "####  FLOW_FROM THE DIRECTORY - is used to get the labels from the directory folders so do not want to add labels manually\n",
    "#### TARGET_SIZE - this must be same as the input shape in the convolution layers\n",
    "#### CLASS_MODE - moode of the classificating either the binary(only comes output as true or false becase its not fitting to this project) or categoroal (suitable for multi class classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory('E:\\\\ALL_ABOUT_SDGP\\\\myBestDataset2\\\\validation',\n",
    "                                            target_size=(64,64),\n",
    "                                            batch_size=12,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd8f76",
   "metadata": {},
   "source": [
    "### STEP 10- FIT THE TRAINING AND TESTING  IMAGES TO THE MODEL\n",
    "##### STEPS_PER_EPOCH - all the training images\n",
    "##### EPOCHS - TOTAL OF ITERTATION OF THE TRAINING( *****THIS SHOULD ME DEVISIBLE BY THE BTACH SIZE******)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828efc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model_hist=sdgp_model.fit(training_set,\n",
    "                         steps_per_epoch=len(training_set),\n",
    "                         epochs = 20, # Total no. of epochs\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = len(test_set)) # Total testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0471e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdgp_model.save(\"E:\\\\ALL_ABOUT_SDGP\\\\finalModelTraining\\\\sdgpModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b87c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
